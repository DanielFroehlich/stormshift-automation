---


# ------------------------------------------------------------------------------
# This customizes the OpenShift V4 Installation
# Heavily inspired / re-used from
# https://github.com/RedHat-EMEA-SSA-Team/hetzner-ocp4/blob/master/ansible/roles/openshift-4-cluster/tasks/post-install.yml

- name: Configure OpenShift4 from support node
  hosts: "{{layer3_ocp_support_host}}"
  gather_facts: false
  vars_files:
    - cfg/secrets_{{sysctx_instance_name}}.yml
  vars:
    storage_nfs_target_namespace: openshift-nfs-provisioner
    openshift_install_dir: "{{layer3_openshift_install_dir}}"
  tasks:

    - debug:
        msg: "{{openshift_install_dir}}/auth/kubeconfig"
# ------------------------------------------------------------------------------
# Add Red Hat Internal CA to trust chain
# (https://docs.openshift.com/container-platform/4.2/networking/configuring-a-custom-pki.html#nw-proxy-configure-object_configuring-a-custom-pki)
# In IPI Installs, the CA Chain is already in user-ca-bundle ConfigMap, thanks to install
# config "additionalTrustBundle" (see there).
# In Non-IPI Installs (e.g. Assisted Installer), we need to add it. so no harm to add it now:
    - name: Add Red Hat Internal CA to user-ca-bundle
      tags: certs
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        merge_type: merge
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: user-ca-bundle
            namespace: openshift-config
          data:
            ca-bundle.crt: |
              {{lookup('file', '{{sysctx_certs_path}}/redhat-pki-ca-chain.crt') | indent(0,true) }}

# Now add it to the Cluster Proxy Config
# ------------------------------------------------------------------------------
    - name: Add user-ca-bundle to cluster proxy config
      tags: certs
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        merge_type: merge
        definition:
          apiVersion: config.openshift.io/v1
          kind: Proxy
          metadata:
            name: cluster
          spec:
            trustedCA:
              name: "user-ca-bundle"

# ------------------------------------------------------------------------------
# Install Certs to Ingress Operator
# ------------------------------------------------------------------------------
# https://docs.openshift.com/container-platform/4.14/security/certificates/replacing-default-ingress-certificate.html
    - name: Create secret with certificates for ingress
      tags: certs
      when: sysctx_certs_path is defined
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        definition:
          apiVersion: v1
          kind: Secret
          data:
            tls.crt: "{{  lookup('file', '{{sysctx_certs_path}}/stormshift_fullchain.crt', rstrip=false) | b64encode }}"
            tls.key: "{{  lookup('file', '{{sysctx_certs_path}}/stormshift.key', rstrip=false)  | b64encode }}"
          metadata:
            name: stormshift-router-certs
            namespace: openshift-ingress
          type: kubernetes.io/tls

    - name: Patch ingresscontroller/default
      tags: certs
      when: sysctx_certs_path is defined
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        merge_type: merge
        definition:
          apiVersion: operator.openshift.io/v1
          kind: IngressController
          metadata:
            name: default
            namespace: openshift-ingress-operator
          spec:
            defaultCertificate:
              name: stormshift-router-certs
# ------------------------------------------------------------------------------
# Install Certs to API Operator
# ------------------------------------------------------------------------------
# Docs for this: https://docs.openshift.com/container-platform/4.14/security/certificates/api-server.html
    - name: Create secret with certificates for API
      tags: certs
      when: sysctx_certs_path is defined
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        definition:
          apiVersion: v1
          kind: Secret
          data:
            tls.crt: "{{  lookup('file', '{{sysctx_certs_path}}/stormshift_fullchain.crt', rstrip=false) | b64encode }}"
            tls.key: "{{  lookup('file', '{{sysctx_certs_path}}/stormshift.key', rstrip=false)  | b64encode }}"
          metadata:
            name: stormshift-api-server-cert
            namespace: openshift-config
          type: kubernetes.io/tls

    - name: Patch cert into apiserver
      tags: certs
      when: sysctx_certs_path is defined
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        merge_type: merge
        definition:
          apiVersion: config.openshift.io/v1
          kind: APIServer
          metadata:
            name: cluster
          spec:
            servingCerts:
              namedCertificates:
              - names:
                - api.{{layer3_ocp_name}}.{{sysctx_dns_domain}}
                servingCertificate:
                  name: stormshift-api-server-cert
# Note: need to remove "certificate-authority-data" from local kubeconfig
# as it creates the self signed cert which is no longer validate.
# This is done at that at the end of this playbook
# not to shoot ourself in the foot because of a maybe invalid kubeconifg


# ------------------------------------------------------------------------------
# Configure authentication
# ------------------------------------------------------------------------------
    - name: "Set Identify Providers to empty"
      set_fact:
        identity_providers: []
      tags: auth

    - name: Add admin users to htpasswd file
      tags: auth,htpasswd
      local_action:
        module: htpasswd
        path: /tmp/htpasswd.{{layer3_ocp_name}}
        name: "{{item}}"
        password: "{{secret_password}}"
      with_items: "{{layer3_ocp_admin_users}}"
      register: htpasswd

    - name: Add normal users to htpasswd file
      tags: auth,htpasswd
      local_action:
        module: htpasswd
        path: /tmp/htpasswd.{{layer3_ocp_name}}
        name: "{{item.name}}"
        password: "{{item.pswd}}"
      with_items: "{{layer3_ocp_normal_users}}"
      register: htpasswd


    - name: Create htpasswd secret
      tags: auth,htpasswd
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        definition:
          apiVersion: v1
          data:
            htpasswd: "{{ lookup('file', '/tmp/htpasswd.{{layer3_ocp_name}}') | b64encode }}"
          kind: Secret
          metadata:
            name: htpasswd
            namespace: openshift-config
          type: Opaque

    - name: Create htpasswd identity provider template
      tags: auth,htpasswd
      set_fact:
        htpasswd_idp:
          htpasswd:
            fileData:
              name: htpasswd
          mappingMethod: claim
          name: Local
          type: HTPasswd

    - name: Push htpasswd_idp to identity_providers
      tags: auth,htpasswd
      set_fact:
        identity_providers: "{{ identity_providers + [ htpasswd_idp ] }}"

    - name: Create google secret secret
      tags: auth,google
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        definition:
          apiVersion: v1
          data:
            clientSecret: "{{ sysctx_google_auth_client_secret | b64encode }}"
          kind: Secret
          metadata:
            name: google-secret
            namespace: openshift-config
          type: Opaque

    - name: Create google identity provider template
      tags: auth,google
      set_fact:
        redhatsso_idp:
          google:
            clientID: "{{ sysctx_google_auth_client_id }}"
            clientSecret:
              name: google-secret
            hostedDomain: redhat.com
          mappingMethod: claim
          name: RedHatInternalSSO
          type: Google

    - name: Push google to identity_providers
      tags: auth,google
      set_fact:
        identity_providers: "{{ identity_providers + [ redhatsso_idp ] }}"

    - name: Configure identity providers
      tags: auth
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        definition:
            apiVersion: config.openshift.io/v1
            kind: OAuth
            metadata:
              name: cluster
            spec:
              identityProviders: "{{ identity_providers }}"

    - name: Add cluster-admin role to admins
      tags: auth
      k8s:
        state: present
        kubeconfig: "{{openshift_install_dir}}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: ClusterRoleBinding
          apiVersion: rbac.authorization.k8s.io/v1
          metadata:
            name: "cluster-admin-{{ item }}"
          subjects:
          - apiGroup: rbac.authorization.k8s.io
            kind: User
            name: "{{ item }}"
          roleRef:
            kind: ClusterRole
            name: "cluster-admin"
      with_items: "{{layer3_ocp_admin_users}}"

# ------------------------------------------------------------------------------
# Create DYNAMIC NFS nfs-client-provisioner until OCS is availabl
# Stolen from:
# https://github.com/RedHat-EMEA-SSA-Team/hetzner-ocp4/blob/master/ansible/roles/openshift-4-cluster/tasks/post-install-storage-nfs.yml
# ------------------------------------------------------------------------------
    - name: Create Namespace
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: Namespace
          apiVersion: v1
          metadata:
            name: "{{ storage_nfs_target_namespace }}"

    - name: Create ServiceAccount
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: ServiceAccount
          apiVersion: v1
          metadata:
            name: nfs-client-provisioner
            namespace: "{{ storage_nfs_target_namespace }}"

    - name: Create ClusteRole nfs-client-provisioner-runner
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: ClusterRole
          apiVersion: rbac.authorization.k8s.io/v1
          metadata:
            name: nfs-client-provisioner-runner
          rules:
            - apiGroups: [""]
              resources: ["persistentvolumes"]
              verbs: ["get", "list", "watch", "create", "delete"]
            - apiGroups: [""]
              resources: ["persistentvolumeclaims"]
              verbs: ["get", "list", "watch", "update"]
            - apiGroups: ["storage.k8s.io"]
              resources: ["storageclasses"]
              verbs: ["get", "list", "watch"]
            - apiGroups: [""]
              resources: ["events"]
              verbs: ["create", "update", "patch"]

    - name: Create ClusteRoleBinding nfs-client-provisioner-runner <-> nfs-client-provisioner
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: ClusterRoleBinding
          apiVersion: rbac.authorization.k8s.io/v1
          metadata:
            name: run-nfs-client-provisioner
          subjects:
            - kind: ServiceAccount
              name: nfs-client-provisioner
              namespace: "{{ storage_nfs_target_namespace }}"
          roleRef:
            kind: ClusterRole
            name: nfs-client-provisioner-runner
            apiGroup: rbac.authorization.k8s.io

    - name: Create Role leader-locking-nfs-client-provisioner
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: Role
          apiVersion: rbac.authorization.k8s.io/v1
          metadata:
            name: leader-locking-nfs-client-provisioner
            namespace: "{{ storage_nfs_target_namespace }}"
          rules:
            - apiGroups: [""]
              resources: ["endpoints"]
              verbs: ["get", "list", "watch", "create", "update", "patch"]

    - name: Create RoleBinding leader-locking-nfs-client-provisioner <-> nfs-client-provisioner
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: RoleBinding
          apiVersion: rbac.authorization.k8s.io/v1
          metadata:
            name: leader-locking-nfs-client-provisioner
            namespace: "{{ storage_nfs_target_namespace }}"
          subjects:
            - kind: ServiceAccount
              name: nfs-client-provisioner
          roleRef:
            kind: Role
            name: leader-locking-nfs-client-provisioner
            apiGroup: rbac.authorization.k8s.io

    - name: Add SCC hostmount-anyuid to nfs-client-provisioner
      when: useDynNFS is defined and useDynNFS
      tags: nfsprov
      command: "oc adm policy add-scc-to-user hostmount-anyuid -n {{ storage_nfs_target_namespace }} -z nfs-client-provisioner --kubeconfig {{ openshift_install_dir }}/auth/kubeconfig"

    - name: Deploy nfs-provisioner
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: Deployment
          apiVersion: apps/v1
          metadata:
            name: nfs-client-provisioner
            namespace: "{{ storage_nfs_target_namespace }}"
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: nfs-client-provisioner
            strategy:
              type: Recreate
            template:
              metadata:
                labels:
                  app: nfs-client-provisioner
              spec:
                serviceAccountName: nfs-client-provisioner
                containers:
                  - name: nfs-client-provisioner
                    image: quay.io/external_storage/nfs-client-provisioner:latest
                    volumeMounts:
                      - name: nfs-client-root
                        mountPath: /persistentvolumes
                    env:
                      - name: PROVISIONER_NAME
                        value: redhat-emea-ssa-team/nfs-client-provisioner
                      - name: NFS_SERVER
                        value: "{{layer3_ocp_nfs_server}}"
                      - name: NFS_PATH
                        value: "{{layer3_ocp_nfs_dynprov_path}}"
                volumes:
                  - name: nfs-client-root
                    nfs:
                      server: "{{layer3_ocp_nfs_server}}"
                      path: "{{layer3_ocp_nfs_dynprov_path}}"

    - name: Storage Class
      tags: nfsprov
      when: useDynNFS is defined and useDynNFS
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata:
            name: managed-nfs-storage
            annotations:
              storageclass.kubernetes.io/is-default-class: "true"
          provisioner: redhat-emea-ssa-team/nfs-client-provisioner
          parameters:
            archiveOnDelete: "false"


# ------------------------------------------------------------------------------
# Activate pruning jobs
# ------------------------------------------------------------------------------
    - name: Activate image pruning
      tags: pruning
      k8s:
        state: present
        kubeconfig: "{{ openshift_install_dir }}/auth/kubeconfig"
        validate_certs: false
        definition:
          kind: ImagePruner
          apiVersion: imageregistry.operator.openshift.io/v1
          metadata:
            name: cluster
          spec:
            failedJobsHistoryLimit: 3
            keepTagRevisions: 3
            schedule: "42 4 * * *"
            successfulJobsHistoryLimit: 3
            suspend: false

# ------------------------------------------------------------------------------
# Kubeconfig update:
# ------------------------------------------------------------------------------
    - name: Remove self signed CA from kubeconfig because we have a nice API server cert which is in the trust root of the system
      tags: post,certs
      when: sysctx_certs_path is defined
      delegate_to: 127.0.0.1
      ansible.builtin.lineinfile:
        path: "{{ openshift_install_dir }}/auth/kubeconfig"
        regexp: 'certificate-authority-data'
        state: absent
        backup: true
